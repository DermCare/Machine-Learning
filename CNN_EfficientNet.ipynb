{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons"
      ],
      "metadata": {
        "id": "gLAXGxz5ed51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d10fd0b7-9c8e-49af-9e94-15fd78d73117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/611.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/611.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m409.6/611.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1GWnaWPW3o6",
        "outputId": "83e2aefd-87f2-433f-c713-e8a9698288c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting efficientnet\n",
            "  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7 (from efficientnet)\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.25.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.9.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (3.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (2024.5.22)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (24.0)\n",
            "Installing collected packages: keras-applications, efficientnet\n",
            "Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import efficientnet.keras as effnet"
      ],
      "metadata": {
        "id": "yLLumLV8W8qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Os32fyfH4Cme",
        "outputId": "220505f9-6f51-4978-d977-82bf6a9cdc90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2 as cv\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import EfficientNetB6\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "AUTO = tf.data.experimental.AUTOTUNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "iONb8lpCKCam",
        "outputId": "6b516a3a-2932-43b3-8b29-c7aa4062155a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.14)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.4)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-998cebdc-5480-4d43-8acb-416e20a7b690\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-998cebdc-5480-4d43-8acb-416e20a7b690\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"azkaprivanna\",\"key\":\"841300ca256a5fda39dbb15657efb0a9\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "! pip install kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Dks9FT7ITEOH"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Gb1k114TYbu",
        "outputId": "797d22ba-e741-49f1-f8fb-633dc60d5550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/shubhamgoel27/dermnet\n",
            "License(s): Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)\n",
            "Downloading dermnet.zip to /content\n",
            "100% 1.72G/1.72G [00:27<00:00, 127MB/s]\n",
            "100% 1.72G/1.72G [00:27<00:00, 68.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "! kaggle datasets download shubhamgoel27/dermnet\n",
        "!unzip -q /content/dermnet.zip \\\n",
        "  && rm dermnet.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "inxssyokWC6m"
      },
      "outputs": [],
      "source": [
        "train_dir_path = ['/content/train/Acne and Rosacea Photos', '/content/train/Bullous Disease Photos', '/content/train/Exanthems and Drug Eruptions',\n",
        "            '/content/train/Hair Loss Photos Alopecia and other Hair Diseases', '/content/train/Herpes HPV and other STDs Photos',\n",
        "            '/content/train/Melanoma Skin Cancer Nevi and Moles', '/content/train/Psoriasis pictures Lichen Planus and related diseases',\n",
        "            '/content/train/Systemic Disease', '/content/train/Vascular Tumors', '/content/train/Vasculitis Photos', '/content/train/Urticaria Hives',\n",
        "            '/content/train/Seborrheic Keratoses and other Benign Tumors', '/content/train/Poison Ivy Photos and other Contact Dermatitis',\n",
        "            '/content/train/Light Diseases and Disorders of Pigmentation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2ho0MV9oej6T"
      },
      "outputs": [],
      "source": [
        "test_dir_path2 = ['/content/test/Acne and Rosacea Photos', '/content/test/Bullous Disease Photos', '/content/test/Exanthems and Drug Eruptions',\n",
        "            '/content/test/Hair Loss Photos Alopecia and other Hair Diseases', '/content/test/Herpes HPV and other STDs Photos',\n",
        "            '/content/test/Melanoma Skin Cancer Nevi and Moles', '/content/test/Psoriasis pictures Lichen Planus and related diseases',\n",
        "            '/content/test/Systemic Disease', '/content/test/Vascular Tumors', '/content/test/Vasculitis Photos', '/content/test/Urticaria Hives',\n",
        "            '/content/test/Seborrheic Keratoses and other Benign Tumors', '/content/test/Poison Ivy Photos and other Contact Dermatitis',\n",
        "            '/content/test/Light Diseases and Disorders of Pigmentation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUGLMR8x6SuX",
        "outputId": "0e66af70-2c06-4999-a6b4-5fe3605ca229"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted: /content/train/Acne and Rosacea Photos\n",
            "Deleted: /content/train/Bullous Disease Photos\n",
            "Deleted: /content/train/Exanthems and Drug Eruptions\n",
            "Deleted: /content/train/Hair Loss Photos Alopecia and other Hair Diseases\n",
            "Deleted: /content/train/Herpes HPV and other STDs Photos\n",
            "Deleted: /content/train/Melanoma Skin Cancer Nevi and Moles\n",
            "Deleted: /content/train/Psoriasis pictures Lichen Planus and related diseases\n",
            "Deleted: /content/train/Systemic Disease\n",
            "Deleted: /content/train/Vascular Tumors\n",
            "Deleted: /content/train/Vasculitis Photos\n",
            "Deleted: /content/train/Urticaria Hives\n",
            "Deleted: /content/train/Seborrheic Keratoses and other Benign Tumors\n",
            "Deleted: /content/train/Poison Ivy Photos and other Contact Dermatitis\n",
            "Deleted: /content/train/Light Diseases and Disorders of Pigmentation\n",
            "Deleted: /content/test/Acne and Rosacea Photos\n",
            "Deleted: /content/test/Bullous Disease Photos\n",
            "Deleted: /content/test/Exanthems and Drug Eruptions\n",
            "Deleted: /content/test/Hair Loss Photos Alopecia and other Hair Diseases\n",
            "Deleted: /content/test/Herpes HPV and other STDs Photos\n",
            "Deleted: /content/test/Melanoma Skin Cancer Nevi and Moles\n",
            "Deleted: /content/test/Psoriasis pictures Lichen Planus and related diseases\n",
            "Deleted: /content/test/Systemic Disease\n",
            "Deleted: /content/test/Vascular Tumors\n",
            "Deleted: /content/test/Vasculitis Photos\n",
            "Deleted: /content/test/Urticaria Hives\n",
            "Deleted: /content/test/Seborrheic Keratoses and other Benign Tumors\n",
            "Deleted: /content/test/Poison Ivy Photos and other Contact Dermatitis\n",
            "Deleted: /content/test/Light Diseases and Disorders of Pigmentation\n"
          ]
        }
      ],
      "source": [
        "for path in train_dir_path + test_dir_path2:\n",
        "    if os.path.exists(path):\n",
        "        shutil.rmtree(path)\n",
        "        print(f\"Deleted: {path}\")\n",
        "    else:\n",
        "        print(f\"Does not exist: {path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "train_images = glob('/content/train/*/*.jpg')\n",
        "len(train_images)"
      ],
      "metadata": {
        "id": "-rmjU82IEsiW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ce8a165-7f48-47a5-9d9d-84e43818af40"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7438"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZydbOQS56Vod"
      },
      "outputs": [],
      "source": [
        "images = [path.replace('\\\\', '/') for path in train_images]\n",
        "df = pd.DataFrame({'filepath': images})\n",
        "df['label'] = df['filepath'].str.split('/', expand=True)[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FV4Fzyf6Yl6",
        "outputId": "fa23e0e4-a9d0-48f3-a55e-2ecd8fb0a0ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            filepath  \\\n",
            "0  /content/train/Lupus and other Connective Tiss...   \n",
            "1  /content/train/Lupus and other Connective Tiss...   \n",
            "2  /content/train/Lupus and other Connective Tiss...   \n",
            "3  /content/train/Lupus and other Connective Tiss...   \n",
            "4  /content/train/Lupus and other Connective Tiss...   \n",
            "\n",
            "                                        label  \n",
            "0  Lupus and other Connective Tissue diseases  \n",
            "1  Lupus and other Connective Tissue diseases  \n",
            "2  Lupus and other Connective Tissue diseases  \n",
            "3  Lupus and other Connective Tissue diseases  \n",
            "4  Lupus and other Connective Tissue diseases  \n",
            "                                               filepath  \\\n",
            "7433  /content/train/Warts Molluscum and other Viral...   \n",
            "7434  /content/train/Warts Molluscum and other Viral...   \n",
            "7435  /content/train/Warts Molluscum and other Viral...   \n",
            "7436  /content/train/Warts Molluscum and other Viral...   \n",
            "7437  /content/train/Warts Molluscum and other Viral...   \n",
            "\n",
            "                                           label  \n",
            "7433  Warts Molluscum and other Viral Infections  \n",
            "7434  Warts Molluscum and other Viral Infections  \n",
            "7435  Warts Molluscum and other Viral Infections  \n",
            "7436  Warts Molluscum and other Viral Infections  \n",
            "7437  Warts Molluscum and other Viral Infections  \n"
          ]
        }
      ],
      "source": [
        "print(df.head())\n",
        "print(df.tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xxRX3eNQ6gI7"
      },
      "outputs": [],
      "source": [
        "label_mapping = {\n",
        "    'Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions':0,\n",
        "    'Atopic Dermatitis Photos':1,\n",
        "    'Cellulitis Impetigo and other Bacterial Infections':2,\n",
        "    'Eczema Photos':3,\n",
        "    # 'Light Diseases and Disorders of Pigmentation': 4,\n",
        "    'Lupus and other Connective Tissue diseases': 4,\n",
        "    'Nail Fungus and other Nail Disease': 5,\n",
        "    'Scabies Lyme Disease and other Infestations and Bites': 6,\n",
        "    'Tinea Ringworm Candidiasis and other Fungal Infections': 7,\n",
        "    'Warts Molluscum and other Viral Infections': 8\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "gN1WBpCh6kE_"
      },
      "outputs": [],
      "source": [
        "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
        "  # Data Augmentation\n",
        "  train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=20,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=True,\n",
        "      fill_mode='nearest',\n",
        "      brightness_range=[0.8, 1.2]\n",
        "  )\n",
        "  # Instantiate the ImageDataGenerator class\n",
        "  validation_datagen = ImageDataGenerator(\n",
        "      rescale=1./255\n",
        "  )\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow_from_directory method\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "      directory=TRAINING_DIR,\n",
        "      batch_size=16,\n",
        "      class_mode='categorical',\n",
        "      target_size=(256, 256),\n",
        "      shuffle=True)\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow_from_directory method\n",
        "  validation_generator = validation_datagen.flow_from_directory(\n",
        "      directory=VALIDATION_DIR,\n",
        "      batch_size=16,\n",
        "      class_mode='categorical',\n",
        "      target_size=(256, 256))\n",
        "\n",
        "  return train_generator, validation_generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Dmj1JZYg6n1w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33e39264-f824-417c-e26b-e13de607e46b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7438 images belonging to 9 classes.\n",
            "Found 1864 images belonging to 9 classes.\n"
          ]
        }
      ],
      "source": [
        "# Define the training and validation base directories\n",
        "TRAINING_DIR='/content/train'\n",
        "VALIDATION_DIR='/content/test'\n",
        "\n",
        "train_generator, validation_generator = train_val_generators(TRAINING_DIR, VALIDATION_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lq8rGJ5Q7Dq2"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "    # Model definition\n",
        "    efficientnet_model = effnet.EfficientNetB6(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(256, 256, 3)\n",
        "    )\n",
        "    efficientnet_model.trainable = False\n",
        "\n",
        "    # Add custom layers on top of EfficientNet\n",
        "    # inputs = layers.Input(shape=(256, 256, 3))\n",
        "    # x = layers.Flatten()(inputs)\n",
        "    # x = layers.Dense(256, activation='relu')(x)\n",
        "    # x = layers.BatchNormalization()(x)\n",
        "    # x = layers.Dense(256, activation='relu')(x)\n",
        "    # x = layers.Dropout(0.3)(x)\n",
        "    # x = layers.BatchNormalization()(x)\n",
        "    # outputs = layers.Dense(len(label_mapping), activation='softmax')(x)\n",
        "\n",
        "    # Add custom layers on top of EfficientNet\n",
        "    x = efficientnet_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    # x = Dropout(0.5)(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    # x = Dropout(0.5)(x)\n",
        "    output = Dense(len(label_mapping), activation='softmax')(x)\n",
        "\n",
        "    # Combine the base model with custom layers\n",
        "    # model = Model(inputs, outputs)\n",
        "    model = Model(inputs=efficientnet_model.input, outputs=output)\n",
        "\n",
        "    return model\n",
        "\n",
        "def train_model(model, train_generator, validation_generator):\n",
        "    # Compile the model\n",
        "    optimizer = Adam(learning_rate=0.0001)\n",
        "    model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # early_stopping = EarlyStopping(\n",
        "    #     monitor='val_loss',\n",
        "    #     patience=15,\n",
        "    #     restore_best_weights=True)\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        epochs=50,\n",
        "        validation_data=validation_generator,\n",
        "        # callbacks=[early_stopping],\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and train the model\n",
        "model = build_model()\n",
        "history = train_model(model, train_generator, validation_generator)"
      ],
      "metadata": {
        "id": "J5OINLuIWKAc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2113f0ff-edbb-451c-be94-7cf98b830bcb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b6_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
            "165527152/165527152 [==============================] - 1s 0us/step\n",
            "Epoch 1/50\n",
            "465/465 - 223s - loss: 1.7075 - accuracy: 0.4142 - val_loss: 1.5562 - val_accuracy: 0.4641 - 223s/epoch - 479ms/step\n",
            "Epoch 2/50\n",
            "465/465 - 196s - loss: 1.5463 - accuracy: 0.4672 - val_loss: 1.5029 - val_accuracy: 0.4802 - 196s/epoch - 421ms/step\n",
            "Epoch 3/50\n",
            "465/465 - 198s - loss: 1.5031 - accuracy: 0.4856 - val_loss: 1.4622 - val_accuracy: 0.5038 - 198s/epoch - 425ms/step\n",
            "Epoch 4/50\n",
            "465/465 - 198s - loss: 1.4638 - accuracy: 0.5008 - val_loss: 1.4316 - val_accuracy: 0.5086 - 198s/epoch - 425ms/step\n",
            "Epoch 5/50\n",
            "465/465 - 198s - loss: 1.4263 - accuracy: 0.5132 - val_loss: 1.4143 - val_accuracy: 0.5182 - 198s/epoch - 426ms/step\n",
            "Epoch 6/50\n",
            "465/465 - 196s - loss: 1.3974 - accuracy: 0.5215 - val_loss: 1.3934 - val_accuracy: 0.5306 - 196s/epoch - 421ms/step\n",
            "Epoch 7/50\n",
            "465/465 - 198s - loss: 1.3802 - accuracy: 0.5231 - val_loss: 1.3874 - val_accuracy: 0.5290 - 198s/epoch - 425ms/step\n",
            "Epoch 8/50\n",
            "465/465 - 195s - loss: 1.3544 - accuracy: 0.5409 - val_loss: 1.3907 - val_accuracy: 0.5204 - 195s/epoch - 419ms/step\n",
            "Epoch 9/50\n",
            "465/465 - 196s - loss: 1.3342 - accuracy: 0.5429 - val_loss: 1.3719 - val_accuracy: 0.5381 - 196s/epoch - 421ms/step\n",
            "Epoch 10/50\n",
            "465/465 - 198s - loss: 1.3169 - accuracy: 0.5460 - val_loss: 1.3807 - val_accuracy: 0.5198 - 198s/epoch - 426ms/step\n",
            "Epoch 11/50\n",
            "465/465 - 201s - loss: 1.3107 - accuracy: 0.5520 - val_loss: 1.3473 - val_accuracy: 0.5413 - 201s/epoch - 433ms/step\n",
            "Epoch 12/50\n",
            "465/465 - 197s - loss: 1.2952 - accuracy: 0.5538 - val_loss: 1.3707 - val_accuracy: 0.5338 - 197s/epoch - 423ms/step\n",
            "Epoch 13/50\n",
            "465/465 - 198s - loss: 1.2845 - accuracy: 0.5604 - val_loss: 1.3412 - val_accuracy: 0.5461 - 198s/epoch - 427ms/step\n",
            "Epoch 14/50\n",
            "465/465 - 198s - loss: 1.2700 - accuracy: 0.5637 - val_loss: 1.3282 - val_accuracy: 0.5606 - 198s/epoch - 427ms/step\n",
            "Epoch 15/50\n",
            "465/465 - 201s - loss: 1.2524 - accuracy: 0.5686 - val_loss: 1.3208 - val_accuracy: 0.5569 - 201s/epoch - 432ms/step\n",
            "Epoch 16/50\n",
            "465/465 - 197s - loss: 1.2478 - accuracy: 0.5702 - val_loss: 1.3004 - val_accuracy: 0.5617 - 197s/epoch - 425ms/step\n",
            "Epoch 17/50\n",
            "465/465 - 198s - loss: 1.2153 - accuracy: 0.5840 - val_loss: 1.2972 - val_accuracy: 0.5655 - 198s/epoch - 426ms/step\n",
            "Epoch 18/50\n",
            "465/465 - 200s - loss: 1.2156 - accuracy: 0.5882 - val_loss: 1.2925 - val_accuracy: 0.5697 - 200s/epoch - 430ms/step\n",
            "Epoch 19/50\n",
            "465/465 - 202s - loss: 1.2079 - accuracy: 0.5836 - val_loss: 1.2863 - val_accuracy: 0.5751 - 202s/epoch - 434ms/step\n",
            "Epoch 20/50\n",
            "465/465 - 201s - loss: 1.1892 - accuracy: 0.5894 - val_loss: 1.2817 - val_accuracy: 0.5724 - 201s/epoch - 431ms/step\n",
            "Epoch 21/50\n",
            "465/465 - 200s - loss: 1.1907 - accuracy: 0.5891 - val_loss: 1.2836 - val_accuracy: 0.5633 - 200s/epoch - 429ms/step\n",
            "Epoch 22/50\n",
            "465/465 - 197s - loss: 1.1724 - accuracy: 0.6024 - val_loss: 1.2936 - val_accuracy: 0.5628 - 197s/epoch - 424ms/step\n",
            "Epoch 23/50\n",
            "465/465 - 203s - loss: 1.1722 - accuracy: 0.6011 - val_loss: 1.2626 - val_accuracy: 0.5714 - 203s/epoch - 437ms/step\n",
            "Epoch 24/50\n",
            "465/465 - 198s - loss: 1.1370 - accuracy: 0.6106 - val_loss: 1.2776 - val_accuracy: 0.5671 - 198s/epoch - 425ms/step\n",
            "Epoch 25/50\n",
            "465/465 - 197s - loss: 1.1558 - accuracy: 0.6049 - val_loss: 1.2612 - val_accuracy: 0.5601 - 197s/epoch - 423ms/step\n",
            "Epoch 26/50\n",
            "465/465 - 198s - loss: 1.1335 - accuracy: 0.6145 - val_loss: 1.2532 - val_accuracy: 0.5810 - 198s/epoch - 426ms/step\n",
            "Epoch 27/50\n",
            "465/465 - 199s - loss: 1.1365 - accuracy: 0.6097 - val_loss: 1.2648 - val_accuracy: 0.5805 - 199s/epoch - 428ms/step\n",
            "Epoch 28/50\n",
            "465/465 - 200s - loss: 1.1340 - accuracy: 0.6074 - val_loss: 1.2725 - val_accuracy: 0.5799 - 200s/epoch - 430ms/step\n",
            "Epoch 29/50\n",
            "465/465 - 196s - loss: 1.1125 - accuracy: 0.6194 - val_loss: 1.2486 - val_accuracy: 0.5735 - 196s/epoch - 422ms/step\n",
            "Epoch 30/50\n",
            "465/465 - 198s - loss: 1.1025 - accuracy: 0.6190 - val_loss: 1.2439 - val_accuracy: 0.5901 - 198s/epoch - 426ms/step\n",
            "Epoch 31/50\n",
            "465/465 - 197s - loss: 1.1054 - accuracy: 0.6234 - val_loss: 1.2465 - val_accuracy: 0.5842 - 197s/epoch - 424ms/step\n",
            "Epoch 32/50\n",
            "465/465 - 198s - loss: 1.0925 - accuracy: 0.6300 - val_loss: 1.2389 - val_accuracy: 0.5907 - 198s/epoch - 427ms/step\n",
            "Epoch 33/50\n",
            "465/465 - 198s - loss: 1.0650 - accuracy: 0.6363 - val_loss: 1.2498 - val_accuracy: 0.5767 - 198s/epoch - 425ms/step\n",
            "Epoch 34/50\n",
            "465/465 - 199s - loss: 1.0769 - accuracy: 0.6359 - val_loss: 1.2593 - val_accuracy: 0.5735 - 199s/epoch - 427ms/step\n",
            "Epoch 35/50\n",
            "465/465 - 198s - loss: 1.0675 - accuracy: 0.6343 - val_loss: 1.2436 - val_accuracy: 0.5773 - 198s/epoch - 426ms/step\n",
            "Epoch 36/50\n",
            "465/465 - 200s - loss: 1.0532 - accuracy: 0.6409 - val_loss: 1.2087 - val_accuracy: 0.5966 - 200s/epoch - 429ms/step\n",
            "Epoch 37/50\n",
            "465/465 - 202s - loss: 1.0595 - accuracy: 0.6408 - val_loss: 1.2218 - val_accuracy: 0.5982 - 202s/epoch - 435ms/step\n",
            "Epoch 38/50\n",
            "465/465 - 201s - loss: 1.0440 - accuracy: 0.6375 - val_loss: 1.2475 - val_accuracy: 0.5740 - 201s/epoch - 433ms/step\n",
            "Epoch 39/50\n",
            "465/465 - 200s - loss: 1.0378 - accuracy: 0.6377 - val_loss: 1.2351 - val_accuracy: 0.5901 - 200s/epoch - 430ms/step\n",
            "Epoch 40/50\n",
            "465/465 - 201s - loss: 1.0280 - accuracy: 0.6526 - val_loss: 1.2447 - val_accuracy: 0.6025 - 201s/epoch - 431ms/step\n",
            "Epoch 41/50\n",
            "465/465 - 201s - loss: 1.0279 - accuracy: 0.6527 - val_loss: 1.2131 - val_accuracy: 0.5971 - 201s/epoch - 432ms/step\n",
            "Epoch 42/50\n",
            "465/465 - 201s - loss: 1.0096 - accuracy: 0.6596 - val_loss: 1.2269 - val_accuracy: 0.5944 - 201s/epoch - 431ms/step\n",
            "Epoch 43/50\n",
            "465/465 - 201s - loss: 1.0037 - accuracy: 0.6550 - val_loss: 1.2470 - val_accuracy: 0.5842 - 201s/epoch - 432ms/step\n",
            "Epoch 44/50\n",
            "465/465 - 201s - loss: 1.0065 - accuracy: 0.6553 - val_loss: 1.2107 - val_accuracy: 0.5976 - 201s/epoch - 431ms/step\n",
            "Epoch 45/50\n",
            "465/465 - 199s - loss: 0.9923 - accuracy: 0.6616 - val_loss: 1.1951 - val_accuracy: 0.6127 - 199s/epoch - 429ms/step\n",
            "Epoch 46/50\n",
            "465/465 - 200s - loss: 0.9836 - accuracy: 0.6656 - val_loss: 1.2280 - val_accuracy: 0.5885 - 200s/epoch - 430ms/step\n",
            "Epoch 47/50\n",
            "465/465 - 199s - loss: 0.9876 - accuracy: 0.6638 - val_loss: 1.1990 - val_accuracy: 0.6003 - 199s/epoch - 427ms/step\n",
            "Epoch 48/50\n",
            "465/465 - 198s - loss: 0.9777 - accuracy: 0.6681 - val_loss: 1.2029 - val_accuracy: 0.5976 - 198s/epoch - 426ms/step\n",
            "Epoch 49/50\n",
            "465/465 - 197s - loss: 0.9724 - accuracy: 0.6701 - val_loss: 1.2040 - val_accuracy: 0.5992 - 197s/epoch - 424ms/step\n",
            "Epoch 50/50\n",
            "465/465 - 199s - loss: 0.9687 - accuracy: 0.6659 - val_loss: 1.2049 - val_accuracy: 0.6019 - 199s/epoch - 428ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fine_tune_model(model, train_generator, validation_generator):\n",
        "    for layer in model.layers[-20:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=20,\n",
        "        restore_best_weights=True)\n",
        "\n",
        "    history_fine = model.fit(\n",
        "        train_generator,\n",
        "        epochs=40,\n",
        "        validation_data=validation_generator,\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    return history_fine\n",
        "\n",
        "# Fine-tune the model\n",
        "history_fine = fine_tune_model(model, train_generator, validation_generator)"
      ],
      "metadata": {
        "id": "PyGhqA2-WCHn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48ccb693-eb05-4c9e-803a-1285e67180e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "465/465 - 223s - loss: 1.1854 - accuracy: 0.5929 - val_loss: 1.2632 - val_accuracy: 0.5810 - 223s/epoch - 480ms/step\n",
            "Epoch 2/40\n",
            "465/465 - 199s - loss: 1.1249 - accuracy: 0.6136 - val_loss: 1.2798 - val_accuracy: 0.5794 - 199s/epoch - 428ms/step\n",
            "Epoch 3/40\n",
            "465/465 - 200s - loss: 1.0924 - accuracy: 0.6304 - val_loss: 1.2855 - val_accuracy: 0.5821 - 200s/epoch - 430ms/step\n",
            "Epoch 4/40\n",
            "465/465 - 200s - loss: 1.0606 - accuracy: 0.6361 - val_loss: 1.2207 - val_accuracy: 0.5992 - 200s/epoch - 431ms/step\n",
            "Epoch 5/40\n",
            "465/465 - 201s - loss: 1.0433 - accuracy: 0.6409 - val_loss: 1.2392 - val_accuracy: 0.5880 - 201s/epoch - 432ms/step\n",
            "Epoch 6/40\n",
            "465/465 - 200s - loss: 1.0072 - accuracy: 0.6533 - val_loss: 1.2136 - val_accuracy: 0.5998 - 200s/epoch - 430ms/step\n",
            "Epoch 7/40\n",
            "465/465 - 200s - loss: 0.9826 - accuracy: 0.6608 - val_loss: 1.2114 - val_accuracy: 0.6025 - 200s/epoch - 430ms/step\n",
            "Epoch 8/40\n",
            "465/465 - 199s - loss: 0.9715 - accuracy: 0.6590 - val_loss: 1.2113 - val_accuracy: 0.5901 - 199s/epoch - 429ms/step\n",
            "Epoch 9/40\n",
            "465/465 - 199s - loss: 0.9532 - accuracy: 0.6701 - val_loss: 1.2075 - val_accuracy: 0.5923 - 199s/epoch - 428ms/step\n",
            "Epoch 10/40\n",
            "465/465 - 198s - loss: 0.9546 - accuracy: 0.6713 - val_loss: 1.2112 - val_accuracy: 0.6089 - 198s/epoch - 427ms/step\n",
            "Epoch 11/40\n",
            "465/465 - 199s - loss: 0.9415 - accuracy: 0.6804 - val_loss: 1.2050 - val_accuracy: 0.6078 - 199s/epoch - 429ms/step\n",
            "Epoch 12/40\n",
            "465/465 - 198s - loss: 0.9130 - accuracy: 0.6892 - val_loss: 1.2201 - val_accuracy: 0.6105 - 198s/epoch - 426ms/step\n",
            "Epoch 13/40\n",
            "465/465 - 199s - loss: 0.9042 - accuracy: 0.6871 - val_loss: 1.1840 - val_accuracy: 0.6255 - 199s/epoch - 427ms/step\n",
            "Epoch 14/40\n",
            "465/465 - 199s - loss: 0.8911 - accuracy: 0.6889 - val_loss: 1.1739 - val_accuracy: 0.6164 - 199s/epoch - 429ms/step\n",
            "Epoch 15/40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Hq1-XEs7WVk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "outputId": "3b177944-2cb7-4109-e049-59ff14f5fda7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb6_notop.h5\n",
            "165234480/165234480 [==============================] - 8s 0us/step\n",
            "Epoch 1/50\n",
            "642/642 - 628s - loss: 2.0789 - accuracy: 0.3312 - val_loss: 2.1475 - val_accuracy: 0.3152 - 628s/epoch - 979ms/step\n",
            "Epoch 2/50\n",
            "642/642 - 532s - loss: 1.6572 - accuracy: 0.4759 - val_loss: 1.7456 - val_accuracy: 0.4567 - 532s/epoch - 829ms/step\n",
            "Epoch 3/50\n",
            "642/642 - 517s - loss: 1.4141 - accuracy: 0.5554 - val_loss: 1.5115 - val_accuracy: 0.5138 - 517s/epoch - 806ms/step\n",
            "Epoch 4/50\n",
            "642/642 - 516s - loss: 1.2143 - accuracy: 0.6148 - val_loss: 1.9601 - val_accuracy: 0.3988 - 516s/epoch - 804ms/step\n",
            "Epoch 5/50\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-2e85fa106bf8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-0e7da9957cb4>\u001b[0m in \u001b[0;36mtrain_models\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     history = model.fit(\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# train_models()\n",
        "# Save training results\n",
        "results = pd.DataFrame({\n",
        "    'Model': ['EfficientNetB2'],\n",
        "    'Train Accuracy': [np.max(history.history['accuracy'])],\n",
        "    'Test Accuracy': [np.max(history.history['val_accuracy'])]\n",
        "})\n",
        "\n",
        "results_fine = pd.DataFrame({\n",
        "    'Model': ['EfficientNetB2 (Fine-Tuned)'],\n",
        "    'Train Accuracy': [np.max(history_fine.history['accuracy'])],\n",
        "    'Test Accuracy': [np.max(history_fine.history['val_accuracy'])]\n",
        "})\n",
        "\n",
        "final_results = pd.concat([results, results_fine], ignore_index=True)\n",
        "print(final_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWG_TZ8LGO2S"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6glK-5HxowMp"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "\n",
        "images = glob('/content/train/*/*.jpg')\n",
        "len(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5BJy-LOpSRF"
      },
      "outputs": [],
      "source": [
        "#replace backslash with forward slash to avoid unexpected errors\n",
        "import pandas as pd\n",
        "\n",
        "images = [path.replace('\\\\', '/') for path in images]\n",
        "df = pd.DataFrame({'filepath': images})\n",
        "df['label'] = df['filepath'].str.split('/', expand=True)[3]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKxCQuXTqc_1"
      },
      "outputs": [],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LRlAFojyehQ"
      },
      "outputs": [],
      "source": [
        "# NKI\n",
        "Actinic_Keratosis = df['label'].values[df['label'].str.contains('Actinic_Keratosis')].tolist()\n",
        "Atopic_Dermatitis= df['label'].values[df['label'].str.contains('Atopic_Dermatitis')].tolist()\n",
        "Cellulitis_Impetigo= df['label'].values[df['label'].str.contains('Cellulitis_Impetigo')].tolist()\n",
        "Eczema= df['label'].values[df['label'].str.contains('Eczema')].tolist()\n",
        "Light_Diseases= df['label'].values[df['label'].str.contains('Light_Diseases')].tolist()\n",
        "Lupus= df['label'].values[df['label'].str.contains('Lupus')].tolist()\n",
        "Nail_Fungus= df['label'].values[df['label'].str.contains('Nail_Fungus')].tolist()\n",
        "Poison_Ivy = df['label'].values[df['label'].str.contains('Poison_Ivy')].tolist()\n",
        "Scabies= df['label'].values[df['label'].str.contains('Scabies')].tolist()\n",
        "Seborrheic_Keratoses= df['label'].values[df['label'].str.contains('Seborrheic_Keratoses')].tolist()\n",
        "Tinea_Ringworm= df['label'].values[df['label'].str.contains('Tinea_Ringworm')].tolist()\n",
        "Urticaria_Hives= df['label'].values[df['label'].str.contains('Urticaria_Hives')].tolist()\n",
        "Vasculitis= df['label'].values[df['label'].str.contains('Vasculitis')].tolist()\n",
        "Warts_Molluscum= df['label'].values[df['label'].str.contains('Warts_Molluscum')].tolist()\n",
        "\n",
        "\n",
        "\n",
        "# Actinic_Keratosis = df['label'].values[df['label'].str.contains('Actinic_Keratosis')].tolist()\n",
        "# Atopic_Dermatitis = df['label'].values[df['label'].str.contains('Atopic_Dermatitis')].tolist()\n",
        "# Cellulitis_Impetigo = df['label'].values[df['label'].str.contains('Cellulitis Impetigo')].tolist()\n",
        "# Eczema = df['label'].values[df['label'].str.contains('Eczema')].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QH_V6fbexmQy"
      },
      "outputs": [],
      "source": [
        "# NKI\n",
        "df_images = {\n",
        "    'Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions':Actinic_Keratosis,\n",
        "    'Atopic Dermatitis Photos':Atopic_Dermatitis,\n",
        "    'Cellulitis Impetigo and other Bacterial Infections':Cellulitis_Impetigo,\n",
        "    'Eczema Photos':Eczema,\n",
        "    'Light Diseases and Disorders of Pigmentation': Light_Diseases,\n",
        "    'Lupus and other Connective Tissue diseases': Lupus,\n",
        "    'Nail Fungus and other Nail Disease': Nail_Fungus,\n",
        "    'Poison Ivy Photos and other Contact Dermatitis': Poison_Ivy,\n",
        "    'Scabies Lyme Disease and other Infestations and Bites': Scabies,\n",
        "    'Seborrheic Keratoses and other Benign Tumors': Seborrheic_Keratoses,\n",
        "    'Tinea Ringworm Candidiasis and other Fungal Infections': Tinea_Ringworm,\n",
        "    'Urticaria Hives': Urticaria_Hives,\n",
        "    'Vasculitis Photos': Vasculitis,\n",
        "    'Warts Molluscum and other Viral Infections': Warts_Molluscum\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hnBPHuNOcfi"
      },
      "outputs": [],
      "source": [
        "df_labels = {\n",
        "    'Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions':0,\n",
        "    'Atopic Dermatitis Photos':1,\n",
        "    'Cellulitis Impetigo and other Bacterial Infections':2,\n",
        "    'Eczema Photos':3,\n",
        "    'Light Diseases and Disorders of Pigmentation': 4,\n",
        "    'Lupus and other Connective Tissue diseases': 5,\n",
        "    'Nail Fungus and other Nail Disease': 6,\n",
        "    'Poison Ivy Photos and other Contact Dermatitis': 7,\n",
        "    'Scabies Lyme Disease and other Infestations and Bites': 8,\n",
        "    'Seborrheic Keratoses and other Benign Tumors': 9,\n",
        "    'Tinea Ringworm Candidiasis and other Fungal Infections': 10,\n",
        "    'Urticaria Hives': 11,\n",
        "    'Vasculitis Photos': 12,\n",
        "    'Warts Molluscum and other Viral Infections': 13\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5ZmWV1BiXAW"
      },
      "outputs": [],
      "source": [
        "# NKI\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for label, images in df_images.items():\n",
        "    for image in images:\n",
        "        img = cv.imread(str(image))\n",
        "        if img is None:\n",
        "            print(f\"Failed to read image: {image}\")\n",
        "            continue\n",
        "        img = cv.resize(img, (224, 224))\n",
        "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "        X.append(img)\n",
        "        y.append(df[label])\n",
        "\n",
        "# Convert lists to arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "3a071cf2"
      },
      "outputs": [],
      "source": [
        "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
        "  \"\"\"\n",
        "  Creates the training and validation data generators\n",
        "\n",
        "  Args:\n",
        "    TRAINING_DIR (string): directory path containing the training images\n",
        "    VALIDATION_DIR (string): directory path containing the testing/validation images\n",
        "\n",
        "  Returns:\n",
        "    train_generator, validation_generator - tuple containing the generators\n",
        "  \"\"\"\n",
        "\n",
        "  # # Instantiate the ImageDataGenerator class (don't forget to set the arguments to augment the images)\n",
        "  # train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "  # # Pass in the appropriate arguments to the flow_from_directory method\n",
        "  # train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
        "  #                                                     batch_size=128,\n",
        "  #                                                     class_mode='categorical',\n",
        "  #                                                     target_size=(224, 224),\n",
        "  #                                                     shuffle=True)\n",
        "\n",
        "  # # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
        "  # validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "  # # Pass in the appropriate arguments to the flow_from_directory method\n",
        "  # validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
        "  #                                                               batch_size=64,\n",
        "  #                                                               class_mode='categorical',\n",
        "  #                                                               target_size=(224, 224))\n",
        "  # Data augmentation\n",
        "  train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=20,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest'\n",
        "  )\n",
        "\n",
        "  test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "  train_generator = train_datagen.flow(X_train, y_train, batch_size=32)\n",
        "  validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "  validation_generator = test_datagen.flow(X_test, y_test, batch_size=32)\n",
        "\n",
        "\n",
        "\n",
        "  return train_generator, validation_generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KX34_4OvcY8c"
      },
      "outputs": [],
      "source": [
        "# Define the training and validation base directories\n",
        "TRAINING_DIR='/content/train'\n",
        "VALIDATION_DIR='/content/test'\n",
        "\n",
        "train_generator, validation_generator = train_val_generators(TRAINING_DIR, VALIDATION_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq0NCEhUtjg4"
      },
      "source": [
        "### **SIMPLE CNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fr6i622hKDt"
      },
      "outputs": [],
      "source": [
        "##SIMPLE CNN\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "def create_model():\n",
        "  '''Creates a CNN with 4 convolutional layers'''\n",
        "  modelio = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 3)),\n",
        "      tf.keras.layers.MaxPooling2D(2, 2),\n",
        "      tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(512, activation='relu'),\n",
        "      tf.keras.layers.Dense(14, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  modelio.compile(loss='categorical_crossentropy',\n",
        "                optimizer=Adam(learning_rate=1e-4),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return modelio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdmYxNRAc0kl"
      },
      "outputs": [],
      "source": [
        "# Constant for epochs\n",
        "EPOCHS = 60\n",
        "\n",
        "# Create a new model\n",
        "modelin = create_model()\n",
        "\n",
        "# Train the model\n",
        "history = modelin.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=40,  # 2000 images = batch_size * steps\n",
        "      epochs=EPOCHS,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=40,  # 1000 images = batch_size * steps\n",
        "      verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iwd1_cWPe9D6"
      },
      "outputs": [],
      "source": [
        "def plot_loss_acc(history):\n",
        "  '''Plots the training and validation loss and accuracy from a history object'''\n",
        "  acc = history.history['accuracy']\n",
        "  val_acc = history.history['val_accuracy']\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  epochs = range(len(acc))\n",
        "\n",
        "  plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "  plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "  plt.title('Training and validation accuracy')\n",
        "\n",
        "  plt.figure()\n",
        "\n",
        "  plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "  plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPvvIsbdfIV7"
      },
      "outputs": [],
      "source": [
        "# Plot training results\n",
        "plot_loss_acc(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYVyEYJgtuue"
      },
      "source": [
        "### **FOR WHAT?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcMJGeqUjvWA"
      },
      "outputs": [],
      "source": [
        "#FOR WHAT?\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "train_dataset = image_dataset_from_directory(TRAINING_DIR,\n",
        "                                             shuffle=True,\n",
        "                                             batch_size=256,\n",
        "                                             image_size=(224,224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDOnGI3_4YoK"
      },
      "outputs": [],
      "source": [
        "#FOR WHAT?\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "test_dataset = image_dataset_from_directory(VALIDATION_DIR,\n",
        "                                             shuffle=True,\n",
        "                                             batch_size=64,\n",
        "                                             image_size=(224,224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KsOGuz1q4Vc"
      },
      "outputs": [],
      "source": [
        "#FOR WHAT?\n",
        "class_names = train_dataset.class_names\n",
        "\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dg_521fNwu3k"
      },
      "outputs": [],
      "source": [
        "def get_label_from_path(path):\n",
        "  \"\"\"Returns the class or directory name from a path.\"\"\"\n",
        "  return os.path.basename(path)\n",
        "\n",
        "path = ['/content/train/Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions', '/content/train/Atopic Dermatitis Photos',\n",
        "        '/content/train/Cellulitis Impetigo and other Bacterial Infections', '/content/train/Eczema Photos',\n",
        "        '/content/train/Light Diseases and Disorders of Pigmentation', '/content/train/Lupus and other Connective Tissue diseases',\n",
        "        '/content/train/Lupus and other Connective Tissue diseases', '/content/train/Nail Fungus and other Nail Disease',\n",
        "        '/content/train/Poison Ivy Photos and other Contact Dermatitis', '/content/train/Scabies Lyme Disease and other Infestations and Bites',\n",
        "        '/content/train/Seborrheic Keratoses and other Benign Tumors', '/content/train/Tinea Ringworm Candidiasis and other Fungal Infections',\n",
        "        '/content/train/Urticaria Hives', '/content/train/Vasculitis Photos', '/content/train/Warts Molluscum and other Viral Infections']\n",
        "\n",
        "for x in path:\n",
        "  train_label = get_label_from_path(x)\n",
        "  print(train_label)  # Output: \"class_directory\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VshuQfSNuBoc"
      },
      "source": [
        "### **CALLBACK**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IGLGEQnKNhU"
      },
      "outputs": [],
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 95.0%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.95):\n",
        "      print(\"\\nReached 95.0% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oR-9i9Aft1xz"
      },
      "source": [
        "### **EFFICIENTNETB0**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atKH2MdrBy1D"
      },
      "outputs": [],
      "source": [
        "from keras.applications import EfficientNetB0\n",
        "\n",
        "pre_trained_model = EfficientNetB0(input_shape = (224, 224, 3),\n",
        "                                include_top = False,\n",
        "                                weights = 'imagenet')\n",
        "\n",
        "# Freeze the weights of the layers.\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGjymQ4jH2yu"
      },
      "outputs": [],
      "source": [
        "pre_trained_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLL3h9suHwVB"
      },
      "outputs": [],
      "source": [
        "# Choose `block5c_add` as the last layer of your base model\n",
        "last_layer = pre_trained_model.get_layer('block5c_add')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNl0t4IqKoxT"
      },
      "outputs": [],
      "source": [
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)\n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(14, activation='softmax')(x)\n",
        "\n",
        "# Append the dense network to the base model\n",
        "model = Model(pre_trained_model.input, x)\n",
        "\n",
        "# Print the model summary. See your dense network connected at the end.\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2aKD8cZK4Pe"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(optimizer = Adam(learning_rate=0.001),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "En-iYpY6LIEs"
      },
      "outputs": [],
      "source": [
        "# Train the model.\n",
        "callbacks = myCallback()\n",
        "history = model.fit(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 40,\n",
        "            epochs = 50,\n",
        "            verbose = 2,\n",
        "            callbacks = [callbacks])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykE3-zuCWODC"
      },
      "outputs": [],
      "source": [
        "def plot_hist(hist):\n",
        "    plt.plot(hist.history[\"accuracy\"])\n",
        "    plt.plot(hist.history[\"val_accuracy\"])\n",
        "    plt.title(\"model accuracy\")\n",
        "    plt.ylabel(\"accuracy\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_hist(hist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAPlsauzLgS7"
      },
      "outputs": [],
      "source": [
        "def unfreeze_model(model):\n",
        "    # We unfreeze the top 20 layers while leaving BatchNorm layers frozen\n",
        "    for layer in model.layers[-20:]:\n",
        "        if not isinstance(layer, layers.BatchNormalization):\n",
        "            layer.trainable = True\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=1e-5)\n",
        "    model.compile(\n",
        "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "\n",
        "unfreeze_model(model)\n",
        "\n",
        "epochs = 4  # @param {type: \"slider\", min:4, max:10}\n",
        "hist = model.fit(train_generator, epochs=epochs, validation_data=validation_generator)\n",
        "plot_hist(hist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0QvW_GQMWQd"
      },
      "source": [
        "### **UNET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAgzHWwSNF6B"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5h_QH-5wo_2"
      },
      "source": [
        "### **SAVE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HdkhxVnXWW_"
      },
      "outputs": [],
      "source": [
        "model_save_path = \"./tmp/dummymodel.h5\"\n",
        "modelin.save(model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjuVM8YTUjEu"
      },
      "outputs": [],
      "source": [
        "files.download('/content/tmp/dummymodel.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tta_OpRDTx7b"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflowjs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uPDCxlfWVTxJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8YCvDm4SVxT"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "!tensorflowjs_converter \\\n",
        "    --input_format=keras dummymodel.h5 ./\n",
        "# !tensorflowjs_converter --input_format=keras dummymodel.h5 dummymodel.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PydsT2HGQBAY"
      },
      "outputs": [],
      "source": [
        "!zip dummypol.zip *.bin modelin.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kT6MKnV1wjHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2TDWRSnum95"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}